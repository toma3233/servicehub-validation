# Creating the test and dev pipelines.
If your environment was not generated for you by Service Hub then you must manually create the 2 pipelines that will allow you to deploy a unique environment for your service.

Both the test and development pipelines use the same yaml file, the only difference will be a variable you set in the pipeline that the yaml file uses to decide whether or not to delete the resources the pipeline has created. The test pipeline automatically deletes the resources right after deployment occurs and tests are successful. It is commonly used as a PR Merge Requirement check. In contrast, the development pipeline is used by developers when they want to deploy a unique environment without manually performing the steps. They can download the necessary artifacts and make changes locally to reflect on the unique environment.

## Pre-requisite
You will need a service connection using workload identity federation (federated credentials) with access to your chosen subscriptions. 
- If you do not have one, follow the instruction found in ["Create an app registration with workload identity federation (automatic)"](https://learn.microsoft.com/en-us/azure/devops/pipelines/library/connect-to-azure?view=azure-devops#create-an-app-registration-with-workload-identity-federation-automatic) in order to create a service connection that uses federated credentials to gain access to your subscription. 
- Make sure it has a subscription scope, and that the service connection name matches the value you used in your [env-information file](../config-files/env-information.yaml) for "serviceConnectionName" upon generation.

## Pipeline and variable group creation
1) In your Azure Devops project, either go to the Start Right home page and click on the Governed pipeline, or go to the Pipelines page and click on the New pipeline button. They will direct you to the same location.
2) Select Azure Devops for "Where is your code?"
3) Select your repository
4) Classify your pipeline as **non-production**. It is **NOT** a OneBranch pipeline, so do not select that option.
5) Select the Configure Pipeline button
6) Select "Existing Azure Pipelines YAML file for "Configure your pipeline"
7) Pick the path to be where your [pipeline-files/testServiceResourceAndCode.yaml](testServiceResourceAndCode.yaml) exists.
8) Select the Review Pipeline button
9) Name your pipeline, make sure to be able to differentiate between test and dev when you are creating the 2 pipelines.
10) Select the arrow below the "Save and run" button to select "Save". Running will not work right now as you have not set the necessary variables.
11) Once pipeline is created, select the "Edit" button at the top right of the page for the pipeline.
12) Select the Variables button and add the following variables
    - SUBSCRIPTION_ID: Your chosen subscription for which the pipeline will create resources in.
    - RESOURCES_NAME: Leave it blank upon setting the variable initially, but select the button that says "Let users override this value when running this pipeline". Thus when running the pipeline with default variable it will create a unique id for you, but you can also set it manually for specific runs if you want to label your resources with a specific id. 
    - LOCATION: Your chosen location for resource deployment
    - WORKING_DIRECTORY: Absolute path used for pipeline and script files. If your service directory does not sit under the root directory of the git repo, you would set this variable to the path that points to the service directory. For example, if relevant to the root of your repository, your service directory is teams/servicehub/service_hub_validation_service, you would set this to value to be : "teams/servicehub/service_hub_validation_service/". Make sure to include the trailing slash. If your generated service is at the root of the repo, then set this value to be blank.
    - DELETE: If test pipeline, set to true. If dev pipeline, set to false.
14) Repeat steps 1-12 for the second pipeline. After this you should have 2 pipelines, one for testing and one for developing. However, We still cannot run the pipeline as we need a variable group called ADO_PAT that will store the $READ_PAT value your pipeline will use to access your privately tagged go modules.
15) Select the Library button under Pipelines in the Azure Devops page. 
16) Select the + Variable group button
17) Name the variable group "ADO_PAT"
18) If your READ_PAT is in a key vault select the "Link secrets from an Azure key vault as variables" button and select the relevant information. If you are manually adding the READ_PAT variable, select the Add butoon under Variables and set the var. Unfortunately since internal policy has changed PAT lives to only be 7 days if you manually added the variable you will need to change it weekly. This is why we recommend using a PAT Rotator that automatically generates the variable into the key vault you link to the variable group.
19) You will now be able to run both pipelines. 
    - If your service connection hasn't allowed access for all pipelines, you will have to manually permit the pipeline to use the service connection when you run the pipeline for the first time.


# How the test and dev pipelines function.
The pipeline yaml file that kickstarts the testing pipeline is: [testServiceResourceAndCode.yaml](testServiceResourceAndCode.yaml) 

- All links specific to a microservice point to one of the microservices generated, as an example.

Here are the steps the pipeline takes:
| Job   | Name   |  Order | Dependency | Located where| Description |
|---|---|---|---|---|---|
|<tr><td colspan="6"><center> **Stage 1: creation_stage**</center></td></tr> |
| Test Coverage for a microservice | **serviceDirectoryName**TestCoverage | *1st pipeline job* |Not dependent on anything, so it will run in parallel with GenerateAndPublishEnvConfig as the first job.| First mentioned [here](../basicservice/deployServicePipeline.yaml) and uses [test suite script](../basicservice/server/test/testSuites.sh) and [test coverage script.](../basicservice/server/test/testCoverageOutput.sh) |  This job has 3 tasks, running the test suite check (confirming all folders with go files has a test suite), running the tests to generate the coverage reports, and publishing the coverage reports as an artifact. |
| Generate and publishing the environment config. | GenerateAndPublishEnvConfig | *1st pipeline job* | Not dependent on anything, so it will run in parallel with **serviceDirectoryNameTestCoverage** as the first job.| First mentioned [here](testServiceResourceAndCode.yaml)| This task creates the environment config using an inline script and publishes it as an artifact such that other jobs can access it. It also outputs the unique id as a warning in the pipeline.
|Provisioning shared resources|ProvisionSharedResources|*2nd pipeline job*| Dependent on **GenerateAndPublishEnvConfig**, so it will run in parallel with **serviceDirectoryNameBuildImage** as the second job.|First mentioned [here](testServiceResourceAndCode.yaml). Job uses this [yaml file](../shared-resources/provisionSharedResourcesPipeline.yaml) as a template. And the yaml file uses this [script.](../shared-resources/provisionSharedResources.sh)|This task first downloads the environment config, then uses the AzureCli task with the specified service connection to run a [script](../shared-resources/provisionSharedResources.sh) provisioning the shared resources.|
|<tr><td colspan="6"><center> Below are microservice deployment related tasks. Each mircroservice's jobs run in parallel as they are unrelated. Template mentioned [here](testServiceResourceAndCode.yaml) leads to microservice deployment [yaml](../basicservice/deployServicePipeline.yaml) file</center></td></tr> |
|Build Image |**serviceDirectoryName**BuildImage |*2nd pipeline job*|Dependent on **GenerateAndPublishEnvConfig**, and doesn't need access to resources so it will run in parallel with **ProvisionSharedResources** as the second job.|First mentioned [here](../basicservice/deployServicePipeline.yaml) and uses this [script.](../basicservice/server/test/buildImage.sh)|This task first downloads the environment config, then uses a [script](../basicservice/server/test/buildImage.sh) to take care of building the service image. This job passes in either READPAT or GOPROXY vars depending on if this pipeline is being generated for user's repository or our repository. READPAT allows the docker image to pull the api module from the users repo (dev.azure.com..) while the GOPROXY vars allow the docker image to pull from go.goms.io|
|Build go workspace image |**serviceDirectoryName**BuildWorkspaceImage |*2nd pipeline job*|Dependent on **GenerateAndPublishEnvConfig**, and doesn't need access to resources so it will run in parallel with **serviceDirectoryNameBuildImage** as the second job.|First mentioned [here](../basicservice/deployServicePipeline.yaml) and uses this [script.](../basicservice/server/test/buildImage.sh)|Same job as previous BuildImage except instead of using remote API it uses go.work to build using current api in folder.|
|Provision service resources. |**serviceDirectoryName**ProvisionServiceResources |*3rd pipeline job*|Dependent on **ProvisionSharedResources**, so it will run in parallel with **serviceDirectoryNamePushImage** as the third job.|First mentioned [here](../basicservice/deployServicePipeline.yaml) and uses this [script.](../basicservice/server/test/provisionServiceResources.sh)|This task first downloads the environment config, then uses the AzureCli task with the specified service connection to run a [script](../basicservice/server/test/provisionServiceResources.sh) provisioning service specific resources, and then publishes the created artifacts. (In this case .azuresdk_properties_outputs.yaml that is used in the deploy service task).|
|Push Image |**serviceDirectoryName**PushImage |*3rd pipeline job*| Dependent on **ProvisionSharedResources** and **serviceDirectoryNameBuildImage**, but not reliant on service specific resources so it will run in parallel with **serviceDirectoryNameProvisionServiceResources** as the third job.|First mentioned [here](../basicservice/deployServicePipeline.yaml) and uses this [script.](../basicservice/server/test/pushImage.sh)|This task first downloads the environment config, then uses the AzureCli task with the specified service connection to run a [script](../basicservice/server/test/pushImage.sh) to push the image.|
|Deploying and testing the Service |**serviceDirectoryName**DeployService |*4th pipeline job*| Dependent on **serviceDirectoryNameProvisionServiceResources** and **serviceDirectoryNamePushImage**, so it will run as the fourth job.|First mentioned [here](../basicservice/deployServicePipeline.yaml) and uses this [script.](../basicservice/server/test/deployService.sh)|This task first downloads the environment config, the downloads the artifact that was published in then uses the AzureCli task with the specified service connection to run a [script](../basicservice/server/test/deployService.sh) to deploy the service and then checking if it was deployed as expected by checking if [pods are running](../basicservice/server/test/checkServicePodStatus.sh), and if [logs are as expected](../basicservice/server/test/checkServicePodLogs.sh).|
|<tr><td colspan="6"><center> **Stage 2: deletion_stage**</center></td></tr> |
|<tr><td colspan="6"><center> Automatically run for test pipelines, but can be manually run for dev pipelines</center></td></tr> |
|Deleting Resources |DeleteResourceGroup |*Final pipeline job*| Dependent on **creation_stage**, so it will run as final job.|First first mentioned [here](testServiceResourceAndCode.yaml) and the yaml file uses this [script.](../shared-resources/deleteResourceGroup.sh)|This task uses a [script](../shared-resources/deleteResourceGroup.sh) to take care of deleting the resource group that was created in shared resources, (also indirectly eliminating service specific resources since they were generated in the same resource group). It uses the defined service connection for credentials and it takes in the unique id that was generated in creation_stage|

